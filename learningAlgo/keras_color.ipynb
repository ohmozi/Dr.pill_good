{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 여기부터 CNN모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 64, 64, 16)        768       \n",
      "_________________________________________________________________\n",
      "batch_normalization_50 (Batc (None, 64, 64, 16)        48        \n",
      "_________________________________________________________________\n",
      "activation_50 (Activation)   (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_50 (MaxPooling (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout_50 (Dropout)         (None, 16, 16, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 16, 16, 32)        8192      \n",
      "_________________________________________________________________\n",
      "batch_normalization_51 (Batc (None, 16, 16, 32)        96        \n",
      "_________________________________________________________________\n",
      "activation_51 (Activation)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_51 (MaxPooling (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "dropout_51 (Dropout)         (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "flatten_24 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 4)                 2052      \n",
      "=================================================================\n",
      "Total params: 273,812\n",
      "Trainable params: 273,716\n",
      "Non-trainable params: 96\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import numpy as np\n",
    "\n",
    "# Initialising the CNN\n",
    "# classifier = Sequential()\n",
    "model = Sequential()\n",
    "\n",
    "# Step 1 - Convolution\n",
    "# classifier.add(Conv2D(16, (3, 3), padding='same', activation='relu', input_shape=(224, 224, 3)))\n",
    "# classifier.add(Conv2D(16, (3, 3), activation='relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# classifier.add(Dropout(0.25))\n",
    "\n",
    "# classifier.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "# classifier.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# classifier.add(Dropout(0.25))\n",
    "\n",
    "# classifier.add(Conv2D(32, (3, 3), padding='same', activation='relu'))\n",
    "# classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
    "# classifier.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# classifier.add(Dropout(0.25))\n",
    "\n",
    "# classifier.add(Flatten())\n",
    "# classifier.add(Dense(512, activation='relu'))\n",
    "# classifier.add(Dropout(0.5))\n",
    "# classifier.add(Dense(5, activation='softmax'))\n",
    "\n",
    "model.add(Conv2D(16, (4, 4), padding='same', use_bias=False, input_shape=(64, 64, 3)))   # 사진 사이즈 조정\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.3))        # 앙상블 효과 \n",
    "\n",
    "model.add(Conv2D(32, (4, 4), padding='same', use_bias=False))\n",
    "model.add(BatchNormalization(axis=3, scale=False))\n",
    "model.add(Activation(\"relu\"))\n",
    "#model.add(Flatten())\n",
    "model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "#model.add(Conv2D(64, (4, 4), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization(axis=3, scale=False))\n",
    "#model.add(Activation(\"relu\"))\n",
    "#model.add(Flatten())\n",
    "#model.add(MaxPooling2D(pool_size=(4, 4), strides=(4, 4), padding='same'))\n",
    "#model.add(Dropout(0.3))\n",
    "\n",
    "#model.add(Conv2D(128, (3, 3), padding='same', use_bias=False))\n",
    "#model.add(BatchNormalization(axis=3, scale=False))\n",
    "#model.add(Activation(\"relu\"))\n",
    "model.add(Flatten())\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "#model.add(Dropout(0.25))\n",
    "model.add(Dense(4, activation='softmax'))     # 판단할 카테고리 수  9\n",
    "model.summary()\n",
    "\n",
    "# Compiling the CNN\n",
    "model.compile(optimizer='adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 317 images belonging to 4 classes.\n",
      "Found 80 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "# Part 2 - Fitting the CNN to the images\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "# 데이터셋 불러오기\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)   #스케일링을 줄여주는것 (normalization 적용해보면 더 좋아질 수 있음) \n",
    "                                   #width_shift_range=0.2,\n",
    "                                   #height_shift_range=0.2)\n",
    "                                   #validation_split=0.33)\n",
    "                                   #otation_range=10,\n",
    "                                   #width_shift_range=0.2,\n",
    "                                   #height_shift_range=0.2,\n",
    "                                   #shear_range=0.2)\n",
    "                                   #zoom_range=[0.9, 2.2],\n",
    "                                   #horizontal_flip=True,\n",
    "                                   #vertical_flip=True,\n",
    "                                   #fill_mode='nearest')\n",
    "                                   #validation_split=0.33)\n",
    "\n",
    "#test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('/home/shy9546/Downloads/color/train',   # 훈련시킬 사진 경로\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=13,\n",
    "                                                 target_size = (64, 64),    # 사이즈 지정해주기\n",
    "                                                 batch_size = 15,\n",
    "                                                 #color_mode='grayscale',\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode = 'categorical')\n",
    "                                                 #subset=\"training\")\n",
    "validation_set = train_datagen.flow_from_directory('/home/shy9546/Downloads/color/valid',\n",
    "                                                 shuffle=True,\n",
    "                                                 seed=13,\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 10,\n",
    "                                                 #color_mode='grayscale',\n",
    "                                                 color_mode='rgb',\n",
    "                                                 class_mode = 'categorical')\n",
    "                                                 #subset=\"validation\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 다시 원래 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "22/22 [==============================] - 8s 362ms/step - loss: 1.3012 - acc: 0.6594 - val_loss: 0.1227 - val_acc: 0.9750\n",
      "Epoch 2/15\n",
      "22/22 [==============================] - 4s 165ms/step - loss: 0.2588 - acc: 0.9144 - val_loss: 0.0710 - val_acc: 0.9875\n",
      "Epoch 3/15\n",
      "22/22 [==============================] - 4s 172ms/step - loss: 0.1900 - acc: 0.9265 - val_loss: 0.2359 - val_acc: 0.9125\n",
      "Epoch 4/15\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0914 - acc: 0.9666 - val_loss: 0.4810 - val_acc: 0.7875\n",
      "Epoch 5/15\n",
      "22/22 [==============================] - 4s 170ms/step - loss: 0.0848 - acc: 0.9879 - val_loss: 0.0237 - val_acc: 1.0000\n",
      "Epoch 6/15\n",
      "22/22 [==============================] - 3s 156ms/step - loss: 0.0211 - acc: 0.9939 - val_loss: 0.0135 - val_acc: 1.0000\n",
      "Epoch 7/15\n",
      "22/22 [==============================] - 4s 164ms/step - loss: 0.0603 - acc: 0.9909 - val_loss: 0.0850 - val_acc: 0.9625\n",
      "Epoch 8/15\n",
      "22/22 [==============================] - 3s 157ms/step - loss: 0.0092 - acc: 1.0000 - val_loss: 0.0175 - val_acc: 0.9875\n",
      "Epoch 9/15\n",
      "22/22 [==============================] - 3s 145ms/step - loss: 0.0105 - acc: 0.9970 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 10/15\n",
      "22/22 [==============================] - 3s 154ms/step - loss: 0.0179 - acc: 0.9939 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 11/15\n",
      "22/22 [==============================] - 3s 151ms/step - loss: 0.0260 - acc: 0.9939 - val_loss: 0.0193 - val_acc: 1.0000\n",
      "Epoch 12/15\n",
      "22/22 [==============================] - 4s 162ms/step - loss: 0.0072 - acc: 1.0000 - val_loss: 0.0087 - val_acc: 1.0000\n",
      "Epoch 13/15\n",
      "22/22 [==============================] - 4s 174ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.0065 - val_acc: 1.0000\n",
      "Epoch 14/15\n",
      "22/22 [==============================] - 4s 187ms/step - loss: 0.0032 - acc: 1.0000 - val_loss: 0.0050 - val_acc: 1.0000\n",
      "Epoch 15/15\n",
      "22/22 [==============================] - 3s 123ms/step - loss: 0.0075 - acc: 0.9970 - val_loss: 0.0088 - val_acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('./log.csv', append=True, separator=';')\n",
    "\n",
    "##hist = model.fit_generator(training_set,\n",
    "#                         epochs = 50,   # 반복수 변경가능\n",
    "#                         validation_data = validation_set\n",
    "#                         )\n",
    "STEP_SIZE_TRAIN = training_set.n\n",
    "STEP_SIZE_VALID = validation_set.n\n",
    "model.fit_generator(generator = training_set,\n",
    "                    #steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                   validation_data=validation_set,\n",
    "                    #validation_steps=STEP_SIZE_VALID,\n",
    "                   epochs=15)\n",
    "from keras.models import load_model\n",
    "\n",
    "model.save('cnn_attraction_keras_model_color5.h5')\n",
    "\n",
    "# output = classifier.predict_generator(test_set, steps=5)\n",
    "# print(test_set.class_indices)\n",
    "# print(output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 8 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "prediction_set = train_datagen.flow_from_directory('/home/shy9546/Downloads/color_temp/test1',\n",
    "                                                  target_size=(64,64),\n",
    "                                                  #color_mode='grayscale',\n",
    "                                                  color_mode='rgb',\n",
    "                                                  batch_size=1,\n",
    "                                                  class_mode =None,\n",
    "                                                  shuffle=False,\n",
    "                                                  seed=13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Evaluate --\n",
      "acc: 100.00%\n",
      "-- Predict --\n",
      "8/8 [==============================] - 2s 210ms/step\n",
      "[[7.6740885e-01 1.0530032e-03 8.1495394e-04 2.3072331e-01]\n",
      " [5.8564398e-04 8.0859888e-01 2.4043653e-02 1.6677178e-01]\n",
      " [8.2993170e-04 2.3666643e-01 7.6244467e-01 5.8969763e-05]\n",
      " [1.7586246e-03 4.1207038e-03 2.7640423e-04 9.9384427e-01]\n",
      " [1.1529122e-02 1.3321157e-02 2.1457756e-03 9.7300398e-01]\n",
      " [4.2368183e-06 2.3291336e-01 3.9935482e-04 7.6668304e-01]\n",
      " [2.0348493e-04 8.7782103e-01 1.2106070e-01 9.1471040e-04]\n",
      " [2.5220418e-06 2.1930570e-03 2.8693341e-06 9.9780148e-01]]\n",
      "['blue', 'orange', 'red', 'white', 'white', 'white', 'orange', 'white']\n",
      "['test_data/1.jpg', 'test_data/2.jpg', 'test_data/3.jpg', 'test_data/4.jpg', 'test_data/5.jpg', 'test_data/6.jpg', 'test_data/7.jpg', 'test_data/8.jpg']\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "\n",
    "#model.load('./cnn_attraction_keras_model11.h5')\n",
    "#model.compile(optimizer = 'adam', loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "model = load_model('./cnn_attraction_keras_model_color5.h5')\n",
    "# 모델 평가하기\n",
    "print(\"-- Evaluate --\")\n",
    "\n",
    "scores = model.evaluate_generator(\n",
    "            validation_set)\n",
    "            #steps = 10)\n",
    "\n",
    "print(\"%s: %.2f%%\" %(model.metrics_names[1], scores[1]*100))\n",
    "\n",
    "# 모델 예측하기\n",
    "print(\"-- Predict --\")\n",
    "STEP_SIZE_TEST = prediction_set.n\n",
    "prediction_set.reset()\n",
    "\n",
    "output = model.predict_generator(\n",
    "            prediction_set,\n",
    "            verbose=1)\n",
    "\n",
    "predicted_class_indices = np.argmax(output,axis=1)\n",
    "labels = (training_set.class_indices)\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "predictions = [labels[k] for k in predicted_class_indices]\n",
    "\n",
    "\n",
    "print(output)\n",
    "print(predictions)\n",
    "print(prediction_set.filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
